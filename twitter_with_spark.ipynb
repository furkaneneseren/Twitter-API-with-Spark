{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4dc9419-5953-4508-bdb0-55c74756f439",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Spark\\python\\pyspark\\sql\\context.py:77: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= 2023-01-06 16:32:30 =========\n",
      "========= 2023-01-06 16:32:35 =========\n",
      "+--------------------+-----+\n",
      "|                word|total|\n",
      "+--------------------+-----+\n",
      "|#DangoteSaltArtCh...|    1|\n",
      "|              #7,000|    1|\n",
      "|          #developer|    1|\n",
      "|        #programming|    1|\n",
      "|             #python|    1|\n",
      "+--------------------+-----+\n",
      "\n",
      "========= 2023-01-06 16:32:40 =========\n",
      "+--------------------+-----+\n",
      "|                word|total|\n",
      "+--------------------+-----+\n",
      "|#DangoteSaltArtCh...|    2|\n",
      "|              #7,000|    1|\n",
      "|          #developer|    1|\n",
      "|        #programming|    1|\n",
      "|             #python|    1|\n",
      "|#TOP100KPOPSONGS2022|    1|\n",
      "|                  #1|    1|\n",
      "|            #WithYou|    1|\n",
      "+--------------------+-----+\n",
      "\n",
      "========= 2023-01-06 16:32:45 =========\n",
      "+--------------------+-----+\n",
      "|                word|total|\n",
      "+--------------------+-----+\n",
      "|#DangoteSaltArtCh...|    3|\n",
      "|              #7,000|    1|\n",
      "|          #developer|    1|\n",
      "|        #programming|    1|\n",
      "|             #python|    1|\n",
      "|#TOP100KPOPSONGS2022|    1|\n",
      "|                  #1|    1|\n",
      "|            #WithYou|    1|\n",
      "|              #komik|    1|\n",
      "|            #dagelan|    1|\n",
      "+--------------------+-----+\n",
      "\n",
      "========= 2023-01-06 16:32:50 =========\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import sys\n",
    "import datetime\n",
    "from pyspark.rdd import RDD\n",
    "from pyspark.sql.functions import desc\n",
    "from pyspark.sql import SQLContext, SparkSession, Row\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark import SparkContext, SparkConf\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "\n",
    "def getSparkSessionInstance(sparkConf: SparkConf) -> SparkSession:\n",
    "    if ('sparkSessionSingletonInstance' not in globals()):\n",
    "        globals()['sparkSessionSingletonInstance'] = SparkSession\\\n",
    "            .builder\\\n",
    "            .config(conf=sparkConf)\\\n",
    "            .getOrCreate()\n",
    "    return globals()['sparkSessionSingletonInstance']\n",
    "\n",
    "\n",
    "def send_df_to_dashboard(df):\n",
    "    top_tags = [str(t.word) for t in df.select(\"word\").collect()]\n",
    "    tags_count = [p.total for p in df.select(\"total\").collect()]\n",
    "    url = 'http://localhost:5001/updateData'\n",
    "    request_data = {'label': str(top_tags), 'data': str(tags_count)}\n",
    "    response = requests.post(url, data=request_data)\n",
    "\n",
    "\n",
    "def process(time: datetime.datetime, rdd) -> None:\n",
    "    print(\"========= %s =========\" % str(time))\n",
    "\n",
    "    try:\n",
    "        spark = getSparkSessionInstance(rdd.context.getConf())\n",
    "\n",
    "        rowRdd = rdd.map(lambda w: Row(word=w))\n",
    "\n",
    "        wordsDataFrame = spark.createDataFrame(rowRdd)\n",
    "\n",
    "        wordsDataFrame.createOrReplaceTempView(\"words\")\n",
    "\n",
    "        wordCountsDataFrame = spark.sql(\n",
    "            \"select word, count(*) as total from words group by word order by total desc limit 10\")\n",
    "\n",
    "        wordCountsDataFrame.show()\n",
    "        send_df_to_dashboard(wordCountsDataFrame)\n",
    "    except BaseException:\n",
    "        pass\n",
    "\n",
    "\n",
    "sc = SparkContext(appName=\"Tweeter\")\n",
    "ssc = StreamingContext(sc, 5)\n",
    "sqlContext = SQLContext(sc)\n",
    "socket_stream = ssc.socketTextStream(\"127.0.0.1\", 5554)\n",
    "lines = socket_stream.window(50)\n",
    "\n",
    "ssc.checkpoint(\"checkpoint_TwitterApp\")\n",
    "words = lines.flatMap(lambda line: line.split(\" \")).filter(\n",
    "    lambda word: word.lower().startswith(\"#\"))\n",
    "words.foreachRDD(process)\n",
    "\n",
    "\n",
    "#words = socket_stream.flatMap(lambda line: line.split(\" \"))\n",
    "# hashtags = words.filter(lambda w: '#' in w).map(lambda x: (x, 1))\n",
    "#tags_totals = hashtags.updateStateByKey(aggregate_tags_count)\n",
    "# tags_totals.foreachRDD(process)\n",
    "\n",
    "\n",
    "# Use Parenthesis for multiple lines or use \\.\n",
    "\"\"\"\n",
    "from collections import namedtuple\n",
    "fields = (\"tag\", \"count\" )\n",
    "Tweet = namedtuple( 'Tweet', fields )\n",
    "\n",
    "( lines.flatMap( lambda text: text.split( \" \" ) ) #Splits to a list\n",
    "  .filter( lambda word: word.lower().startswith(\"#\") ) # Checks for hashtag calls\n",
    "  .map( lambda word: ( word.lower(), 1 ) ) # Lower cases the word\n",
    "  .reduceByKey( lambda a, b: a + b ) # Reduces\n",
    "  .map( lambda rec: Tweet( rec[0], rec[1] ) ) # Stores in a Tweet Object\n",
    "  .foreachRDD( lambda rdd: rdd.toDF().sort( (\"count\") ) # Sorts Them in a DF\n",
    "  .limit(10).createOrReplaceTempView (\"tweets\") ) ) # Registers to a table\n",
    "\"\"\"\n",
    "\n",
    "ssc.start()\n",
    "ssc.awaitTermination()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0df697bf",
   "metadata": {},
   "source": [
    "# __Can be added__\n",
    "### Analysis with updated state (with sql context) or can be used DStream object."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "4b04f0dddd9f19c3080a8e843bfac23ef96c1453e4f59dfcd7e6dd8f82dee673"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
